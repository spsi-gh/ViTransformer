{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450dcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../scripts\", exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca836495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../scripts/data_setup.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/data_setup.py\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "import os\n",
    "num_workers = os.cpu_count()\n",
    "\n",
    "def create_dataloaders(transform: torchvision.transforms,\n",
    "                       batch_size:int,\n",
    "                       num_workers:int =num_workers):\n",
    "\n",
    "    data_path = Path = (\"data/\")\n",
    "    IMG_SIZE = 224\n",
    "    train_data = datasets.CIFAR10(root= data_path, \n",
    "                                  train=True,\n",
    "                                  download=True,\n",
    "                                  transform=transform)\n",
    "    test_data = datasets.CIFAR10(root=data_path,\n",
    "                                 train=False,\n",
    "                                 download=True,\n",
    "                                 transform=transform)\n",
    "\n",
    "    class_names = train_data.classes\n",
    "\n",
    "    train_dataloader = DataLoader(train_data,\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_workers=num_workers,\n",
    "                                  shuffle=True,\n",
    "                                  pin_memory=True)\n",
    "    test_dataloader = DataLoader(test_data,\n",
    "                                 batch_size=batch_size,\n",
    "                                 num_workers=num_workers,\n",
    "                                 shuffle=True,\n",
    "                                 pin_memory=True)\n",
    "    \n",
    "    return train_dataloader, test_dataloader, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b8a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../scripts/engine.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../scripts/engine.py\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               device: torch.device) -> Tuple[float, float]:\n",
    "\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "      X, y = X.to(device), y.to(device)\n",
    "\n",
    "      y_logits = model(X)\n",
    "      y_pred = torch.softmax(y_logits, dim = 1).argmax(dim = 1)\n",
    "      loss = loss_fn(y_logits, y)\n",
    "      train_loss += loss.item()\n",
    "      train_acc += (y_pred == y).sum().item()/len(y_pred)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "              dataloader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module,\n",
    "              optimizer: torch.optim.Optimizer,\n",
    "              device: torch.device) -> Tuple[float, float]:\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    test_loss, test_acc = 0, 0\n",
    "    with torch.inference_mode():\n",
    "      for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        test_logits = model(X)\n",
    "        test_loss += loss_fn(test_logits, y).item()\n",
    "\n",
    "        test_pred = torch.softmax(test_logits, dim = 1).argmax(dim = 1)\n",
    "        test_acc += (test_pred == y).sum().item()/len(test_pred)\n",
    "\n",
    "      test_loss /= len(dataloader)\n",
    "      test_acc /= len(dataloader)\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_fn: torch.nn.Module,\n",
    "          device: torch.device,\n",
    "          epochs: int,\n",
    "          optimizer: torch.optim.Optimizer) -> Dict[str, List]:\n",
    "\n",
    "\n",
    "    result = {\n",
    "            \"train_loss\": [],\n",
    "            \"train_acc\": [],\n",
    "            \"test_loss\": [],\n",
    "            \"test_acc\": []\n",
    "    }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "      train_loss, train_acc = train_step(model = model,\n",
    "                                         dataloader=train_dataloader,\n",
    "                                         loss_fn = loss_fn,\n",
    "                                         optimizer=optimizer,\n",
    "                                         device = device)\n",
    "      test_loss, test_acc = test_step(model = model,\n",
    "                                         dataloader=test_dataloader,\n",
    "                                         loss_fn = loss_fn,\n",
    "                                         optimizer=optimizer,\n",
    "                                         device = device)\n",
    "\n",
    "      print(f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f} | \"\n",
    "            )\n",
    "\n",
    "      result[\"train_loss\"].append(train_loss)\n",
    "      result[\"train_acc\"].append(train_acc)\n",
    "      result[\"test_loss\"].append(test_loss)\n",
    "      result[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208cef86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
