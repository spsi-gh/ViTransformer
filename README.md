# ViTransformer

A Vision Transformer (ViT) implementation with CUDA-accelerated custom GELU kernel. This project is modularized into notebooks for experimentation, scripts for training pipeline, and CUDA for performance-critical operations.

---

## ğŸ§  Model Summary

- **Dataset**: CIFAR-10 (32Ã—32 RGB images)
- **Image Size**: 32Ã—32
- **Patch Size**: 4Ã—4
- **Number of Patches**: 64
- **Architecture**: Transformer encoder with learnable class token
- **Activation**: Custom CUDA GELU
- **Framework**: PyTorch + custom CUDA extension
  
---

## ğŸ“ Project Structure

ViTransformer/
â”‚
â”œâ”€â”€ notebook/
â”‚ â”œâ”€â”€ ViT.ipynb # Main model experimentation
â”‚ â””â”€â”€ setup.ipynb # Setup and testing utilities
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ datasetup.py # Dataset download and preprocessing
â”‚ â””â”€â”€ engine.py # Training and evaluation loops
â”‚
â”œâ”€â”€ kernel/
â”‚ â”œâ”€â”€ gelu_cuda.cu # CUDA implementation of GELU activation
â”‚ â””â”€â”€ setup.py # Extension building script

